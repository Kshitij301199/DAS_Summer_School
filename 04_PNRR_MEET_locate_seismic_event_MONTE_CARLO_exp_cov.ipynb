{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter Notebook for locating a seismic event using McMC sampling\n",
    "\n",
    "### TASK:\n",
    "\n",
    "Locate a seismic event within an homogeneous half-space, using P- arrival times. Hypocentral parameters will be found using a \"Markov chain Monte Carlo\" methodology, and including a full Error Covariance matrix (necessary for DAS data)\n",
    "\n",
    "### WORKFLOW:\n",
    "\n",
    "(1) Define data and model space (i.e. prior information about hypocenter parameters)\n",
    "\n",
    "(2) Define the Error Covariance matrix\n",
    "\n",
    "(3) Start the McMC sampling form a random point in the model space\n",
    "\n",
    "(4) Compute Likelihood of the starting model\n",
    "\n",
    "#### Iterate fo N steps in the Markov chain:\n",
    "\n",
    "(3) Modify the _current model_ (the starting model in the first iteration) proposing a _candidate model_ from the prior information\n",
    "\n",
    "(4) Compute the Likelihood of the candidate model\n",
    "\n",
    "(5) Accept or Reject candidate model using Metropolis rule\n",
    "\n",
    "(5.1) If Accepted, the candidate model becomes the current model\n",
    "(5.2) Id Rejected, the current model is kept and the candidate is removed from the chain\n",
    "\n",
    "(6) Every 100 steps in the chain: store the current model\n",
    "\n",
    "(7) Back to (3)\n",
    "\n",
    "#### Post Processing:\n",
    "\n",
    "(8) Extract relevant estimators of the hypocentral parameters from the stored models (eg mean and standard deviation) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "import obspy\n",
    "from obspy import UTCDateTime\n",
    "\n",
    "from IPython.display import Image\n",
    "import matplotlib.image as image \n",
    "\n",
    "#For the McMC sampling\n",
    "from mcmc_locate_exp_cov import npa_candidate_model\n",
    "from mcmc_locate_exp_cov import npa_log_likelihood\n",
    "from mcmc_locate_exp_cov import npa_LOCATE_syn\n",
    "from mcmc_locate_exp_cov import npa_metropolis\n",
    "from mcmc_locate_exp_cov import npa_get_starting_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definizioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "###########################################################################################\n",
    "#\n",
    "# EDIT HERE ---- Baribles used in the Jnotebook for the analysis\n",
    "#\n",
    "#\n",
    "#Seismic source\n",
    "EVENT_NAME=\"TITO_01\"                        # LABEL for creating files\n",
    "event_X=15.8432                             # Approx X coord of the source\n",
    "event_Y=40.6632                             # Approx Y coord of the source\n",
    "datafile=\"data/picks/event.csv\"             # P-wave arrival time at DAS channels \n",
    "cablegeom=\"input/tito_cable_geometry.dat\"   # Coordinates of the sensing FO channels\n",
    "degree_or_meter=\"degree\"                    # Select measure unit for distance in X-Y\n",
    "#\n",
    "############################################################################################\n",
    "#\n",
    "# Derived variables -- \n",
    "#  \n",
    "#   if \"degree\" is set, we expect regional source\n",
    "#   if \"meters\" is set, we expect local source\n",
    "#\n",
    "#   McMC parameter space is set according to.\n",
    "#\n",
    "if degree_or_meter == \"degree\":\n",
    "    dx=1\n",
    "    dy=1\n",
    "    zmax_mcmc=20000\n",
    "    tmin_mcmc=-15\n",
    "    tmax_mcmc=1\n",
    "    vpmin_mcmc=5000.\n",
    "    vpmax_mcmc=7000.\n",
    "    std0=0.1\n",
    "    x_lab=\"Longitude (degree)\"\n",
    "    y_lab=\"Latitude (degree)\"\n",
    "    conv=111194.                  # Approx Degree to meters conversion\n",
    "else:\n",
    "    dx=100\n",
    "    dy=100\n",
    "    zmax_mcmc=10\n",
    "    tmin_mcmc=-0.5\n",
    "    tmax_mcmc=0.5\n",
    "    vpmin_mcmc=500.\n",
    "    vpmax_mcmc=3000.\n",
    "    std0=0.01\n",
    "    x_lab=\"X-UTM (meters)\"\n",
    "    y_lab=\"Y-UTM (meters)\"\n",
    "    conv=1.\n",
    "#\n",
    "# 2D area where the seismic source will be located \n",
    "xmin_mcmc=event_X-dx\n",
    "xmax_mcmc=event_X+dx\n",
    "ymin_mcmc=event_Y-dy\n",
    "ymax_mcmc=event_Y+dy\n",
    "#\n",
    "# Zoom close to the true location of the seismic source\n",
    "xmin_zoom=event_X-dx/2\n",
    "xmax_zoom=event_X+dx/2\n",
    "ymin_zoom=event_Y-dy/2\n",
    "ymax_zoom=event_Y+dy/2\n",
    "#\n",
    "#\n",
    "print(' Selected event: ' + EVENT_NAME)\n",
    "print(' Selected FO cable: ' + cablegeom)\n",
    "print(' Selected data: ' + datafile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map of selected FO cable and approx shot location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ch_pos, y_das, x_das = np.loadtxt(cablegeom, dtype=(float), usecols=(0,1,2), unpack=True)\n",
    "\n",
    "nch_pos=len(x_das)\n",
    "\n",
    "\n",
    "# Plot FO cable trace\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.xlim(xmin_mcmc,xmax_mcmc)\n",
    "plt.ylim(ymin_mcmc,ymax_mcmc)\n",
    "plt.grid()\n",
    "plt.plot(x_das, y_das,'X', markersize=2,c='blue',label='FO cable')\n",
    "plt.plot(event_X, event_Y,marker='*', markersize=20, markerfacecolor='yellow',label='Seismic source')\n",
    "plt.xlabel(x_lab, fontsize=20)\n",
    "plt.ylabel(y_lab,fontsize=20)\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Fiber optic cable + source location ')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data related to selected Shot (i.e. arrival times of P- wave at DAS channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Only channels with P-wave arrivl time are collected\n",
    "# 2. I add the channel location to the array\n",
    "# 3. I convert UTC time in Epoch Time\n",
    "\n",
    "Ppick_orig = np.loadtxt(datafile, delimiter=',', dtype='str', usecols=(1), skiprows=1, unpack=True)\n",
    "ch_orig = np.loadtxt(datafile, delimiter=',', dtype='int', usecols=(3), skiprows=1, unpack=True)\n",
    "ph_orig = np.loadtxt(datafile, delimiter=',', dtype='str', usecols=(2), skiprows=1, unpack=True)\n",
    "\n",
    "nch=len(Ppick_orig)\n",
    "\n",
    "ch_sele = []\n",
    "Ppick_sele = []\n",
    "chlo = []\n",
    "chla = []\n",
    "\n",
    "ich=0\n",
    "while ich<nch:\n",
    "    pick0=Ppick_orig[ich]\n",
    "    ph0=ph_orig[ich]\n",
    "    ch0=ch_orig[ich]\n",
    "    if pick0 != '' and ph0 == 'P':\n",
    "        Ppick_date=pick0.split()[0]\n",
    "        Ppick_time=pick0.split()[1]\n",
    "        utc0= Ppick_date + \"T\" + Ppick_time\n",
    "        Ppick_epoch=UTCDateTime(utc0)\n",
    "        Ppick_sele.append(Ppick_epoch)\n",
    "        ch_sele.append(ch0)\n",
    "        # Select coordinates\n",
    "        ich_all=0\n",
    "        while ich_all < nch_pos:\n",
    "            ch_pos0=ch_pos[ich_all]\n",
    "            if ch_pos0 == ch0:\n",
    "                chlo0=x_das[ich_all]\n",
    "                chla0=y_das[ich_all]\n",
    "                chlo.append(chlo0)\n",
    "                chla.append(chla0)\n",
    "            ich_all+=1        \n",
    "    ich +=1\n",
    "    \n",
    "nch_sele=len(ch_sele)\n",
    "Ppick_sele=np.array(Ppick_sele)\n",
    "min_P_pick = min(Ppick_sele)\n",
    "print('Found', nch_sele, 'stations with associated picking -- earliest P-arrival:', min_P_pick)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map of the selected DAS channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Relative DAS data\n",
    "\n",
    "Ppick = Ppick_sele - min_P_pick\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.xlim(xmin_zoom,xmax_zoom)\n",
    "plt.ylim(ymin_zoom,ymax_zoom)\n",
    "plt.grid()\n",
    "plt.plot(x_das, y_das, '.', markersize=1, c='blue',label='FO cable')\n",
    "plt.scatter(chlo, chla, s=50, c=Ppick, cmap='viridis', label='selected DAS channels')\n",
    "plt.colorbar(label='Relative arrival-times from earliest P-wave arrival time')\n",
    "plt.plot(event_X, event_Y,marker='*', markersize=20, markerfacecolor='yellow',label='Seismic source')\n",
    "plt.xlabel(x_lab, fontsize=16)\n",
    "plt.ylabel(y_lab,fontsize=16)\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Available DAS data ')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Locate the seismic source using a Markov chain Monte Carlo approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#######################################################\n",
    "#######################################################\n",
    "#\n",
    "# EDIT HERE\n",
    "#\n",
    "# Define the model space\n",
    "# (Uniform prior probability distirbution)\n",
    "#\n",
    "xmin=xmin_mcmc  # in m\n",
    "xmax=xmax_mcmc  # in m\n",
    "ymin=ymin_mcmc  # in m\n",
    "ymax=ymax_mcmc  # in m\n",
    "zmin=0.         # in m\n",
    "zmax=zmax_mcmc  # in m\n",
    "tmin=tmin_mcmc  # in s\n",
    "tmax=tmax_mcmc  # in s\n",
    "vpmin=vpmin_mcmc  # in m/s\n",
    "vpmax=vpmax_mcmc  # in m/s\n",
    "\n",
    "# FOR CREATING SYNTHETICS\n",
    "#xmin=15.9       # in m\n",
    "#xmax=17.9       # in m\n",
    "#ymin=40.7       # in m\n",
    "#ymax=40.7       # in m\n",
    "#zmin=0          # in m\n",
    "#zmax=0          # in m\n",
    "#tmin=-3.        # in s\n",
    "#tmax=-3.        # in s\n",
    "#vpmin=6000.0    # in m/s\n",
    "#vpmax=6000.0    # in m/s\n",
    "#\n",
    "\n",
    "#\n",
    "#\n",
    "#   MARKOV CHAIN MONTE CARLO PARAMETERS\n",
    "# \n",
    "N_CHAINS=10                        # Number of chains\n",
    "N_MOD_MCMC=2000                    # Number of samples collected alon the McMC\n",
    "BURN_IN=1000                       # Samples discarded at the beginning of the McMC\n",
    "PRIOR = 0                          # PRIOR SAMPLING: 1- sampling prior information; 0- Monte Carlo sampling \n",
    "#\n",
    "#\n",
    "#   EXPONENTIAL COVARIANCE MATRIX DEFINITIONS\n",
    "#\n",
    "r_corr=0.9\n",
    "#\n",
    "#\n",
    "# RANDOM SEED -- to produce always the same sequence of pseudo-random numbers\n",
    "#\n",
    "rseed=210728\n",
    "rng = np.random.default_rng(rseed)\n",
    "#\n",
    "#######################################################\n",
    "#######################################################\n",
    "#######################################################\n",
    "\n",
    "\n",
    "#######################################################\n",
    "#######################################################\n",
    "#######################################################\n",
    "\n",
    "#\n",
    "# Pre-compute inverse of EXP cov matrix\n",
    "#\n",
    "\n",
    "cor = np.zeros((nch_sele,nch_sele), dtype=float)\n",
    "icov = np.zeros((nch_sele,nch_sele), dtype=float)\n",
    "\n",
    "ir=0\n",
    "while ir < nch_sele:\n",
    "    \n",
    "    if ir == 0:\n",
    "        diag0=1.0+(r_corr**2)\n",
    "    if ir == 1:\n",
    "        diag0=-1.0*r_corr\n",
    "    if ir > 1:\n",
    "        diag0=0.0\n",
    "\n",
    "    ic=ir\n",
    "    while ic < nch_sele:\n",
    "    \n",
    "        cor[ic-ir,ic]=diag0\n",
    "        cor[ic,ic-ir]=diag0\n",
    "    \n",
    "        ic+=1\n",
    "        \n",
    "    ir+=1\n",
    "\n",
    "\n",
    "cor[0,0]=1.0\n",
    "cor[nch_sele-1,nch_sele-1]=1.0\n",
    "\n",
    "ir=0\n",
    "ic=0\n",
    "while ir < nch_sele:\n",
    "    ic=0\n",
    "    while ic < nch_sele:\n",
    "        icov[ir,ic]=(1.0/(1.0-(r_corr**2)))*(1.0/(std0*std0))*cor[ir,ic]\n",
    "        ic += 1\n",
    "    ir += 1\n",
    "    \n",
    "print('\\n PRE-PROCESSING of the INVERSE COV MATRIX: \\n')\n",
    "print(cor,icov)\n",
    "print('\\n INVERSE of an EXPONENTIAL COV MATRIX should be tri-diagonal \\n')\n",
    "\n",
    "#######################################################\n",
    "#######################################################\n",
    "#######################################################\n",
    "\n",
    "\n",
    "#\n",
    "# Initialize vectors for collecting sampled models\n",
    "#\n",
    "ALL_X = []\n",
    "ALL_Y = []\n",
    "ALL_Z = []\n",
    "ALL_T = []\n",
    "ALL_VP = []\n",
    "\n",
    "#\n",
    "#\n",
    "# (1) Campionamento dello spazio dei parametri (ripetuto N volte per M catene di Markov diverse)\n",
    "#\n",
    "ichain = 1 \n",
    "while ichain <= N_CHAINS:\n",
    "    \n",
    "    #\n",
    "    # (2) DEFINE STARTING MODEL as a random point in the model-space\n",
    "    #\n",
    "    X0, Y0, Z0, T0, VP0 = npa_get_starting_model(rng, xmin, xmax, ymin, ymax, zmin, zmax, tmin, tmax, vpmin, vpmax)\n",
    "    #\n",
    "    print('\\n%s\\n%s%8.2f%s%8.2f%s%8.2f%s%8.2f%s%8.2f\\n' % (\"STARTING MODEL:\",  \" - X: \", X0, \" - Y: \", Y0, \" - Z: \", Z0, \" - T0: \", T0, \" - Vp: \", VP0)) \n",
    "    #\n",
    "    # (3.1) COMPUTE SYNTHETICS for starting model\n",
    "    #\n",
    "    SYN_data_P = []\n",
    "    SYN_data_P = npa_LOCATE_syn(nch_sele, chlo, chla, conv, X0, Y0, Z0, T0, VP0)\n",
    "    #\n",
    "    #\n",
    "    # Write out synthetics -- for a synthetic test\n",
    "    #\n",
    "    if N_MOD_MCMC == 0 and ichain == 1:\n",
    "        istat=0\n",
    "        while istat < nch_sele:\n",
    "            x1=chlo[istat]\n",
    "            y1=chla[istat]\n",
    "            ch0=ch_sele[istat]\n",
    "            theo_P=SYN_data_P[istat]   # SYNTHETICS without noise\n",
    "            theo_P=SYN_data_P[istat]+rng.normal(0.0,std0)  # SYNTHETICS with ADDED noise\n",
    "            theo_P=min_P_pick+theo_P\n",
    "            print(\"%d%s%s%s%d\" % (istat,\",\",theo_P,\",P,\",ch0))\n",
    "            istat += 1\n",
    "    \n",
    "    #\n",
    "    #\n",
    "    # (3.2) COMPUTE FIT TO STARTING MODEL\n",
    "    #\n",
    "    lppd0 = npa_log_likelihood(nch_sele, SYN_data_P, Ppick, icov)\n",
    "    #\n",
    "    #\n",
    "    print('\\n LOG LIKELIHOOD starting model: ', lppd0)\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    #    START MCMC\n",
    "    #\n",
    "    #\n",
    "\n",
    "    imod = 1\n",
    "    while imod <= N_MOD_MCMC:\n",
    "    #\n",
    "    #\n",
    "\n",
    "\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    # (4.1) Propose a candidate model as a small preturbation of the current model\n",
    "    #\n",
    "    #\n",
    "        X_cand, Y_cand, Z_cand, T_cand, VP_cand = npa_candidate_model(rng, X0, Y0, Z0, T0, VP0, xmin, xmax, ymin, ymax, zmin, zmax, tmin, tmax, vpmin, vpmax)\n",
    "    #\n",
    "    #\n",
    "\n",
    "        #print(\"%s%10.3f%10.3f%10.3f\" % ('\\n   CURRENT MODEL: ', X0, Y0, Z0))\n",
    "        #print(\"%s%10.3f%10.3f%10.3f\" % (' CANDIDATE MODEL: ', X_cand, Y_cand, Z_cand))\n",
    "\n",
    "    #\n",
    "    #\n",
    "    #  (4.2) Compute predicted data given by the candidate model\n",
    "    #\n",
    "    #\n",
    "        SYN_data_P = []\n",
    "        SYN_data_P = npa_LOCATE_syn(nch_sele, chlo, chla, conv, X_cand, Y_cand, Z_cand, T_cand, VP_cand)\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    # (4.3) Compute the Likelihood between observed data and predicted data\n",
    "    #\n",
    "    #\n",
    "        lppd = npa_log_likelihood(nch_sele, SYN_data_P, Ppick,  icov)\n",
    "\n",
    "        if PRIOR == 1:\n",
    "            lppd0 = 1.0\n",
    "            lppd  = 1.0\n",
    "   \n",
    "    #\n",
    "    #\n",
    "    # (4.4) Apply Metropolis'rule to select between candidate and current model\n",
    "    #\n",
    "    #\n",
    "        Accepted = npa_metropolis(rng, lppd,lppd0)\n",
    "    #\n",
    "    #\n",
    "        if imod % 100 == 0:\n",
    "            print(\"%s%4d%s%9d%s%4d%s%16.2f%16.2f\" % ('CHAIN: ', ichain, ' SAMPLED MODEL: ', imod, '  Accepted:', Accepted, '  LPPD: ', lppd, lppd0))\n",
    "\n",
    "\n",
    "\n",
    "    #\n",
    "    #\n",
    "    # (4.5) Store the selected model for post-processing\n",
    "    #\n",
    "    #\n",
    "    # If the candidate model is rejected, current model becomes candidate model\n",
    "    #\n",
    "        if Accepted == 0:\n",
    "            \n",
    "            X_cand = X0\n",
    "            Y_cand = Y0\n",
    "            Z_cand = Z0\n",
    "            T_cand = T0\n",
    "            VP_cand = VP0\n",
    "            lppd = lppd0\n",
    "\n",
    "    #\n",
    "    # Store candidate model (after BURN-IN phase)\n",
    "    #\n",
    "\n",
    "        if imod >= BURN_IN:\n",
    "            \n",
    "            if imod % 100 == 0:\n",
    "            \n",
    "                ALL_X.append(X_cand)\n",
    "                ALL_Y.append(Y_cand)\n",
    "                ALL_Z.append(Z_cand)\n",
    "                ALL_VP.append(VP_cand)\n",
    "                ALL_T.append(T_cand)\n",
    "\n",
    "    #\n",
    "    # Candidate model becomes current model\n",
    "    #\n",
    "\n",
    "        X0 = X_cand\n",
    "        Y0 = Y_cand\n",
    "        Z0 = Z_cand\n",
    "        T0 = T_cand\n",
    "        VP0 = VP_cand\n",
    "        lppd0 = lppd\n",
    "\n",
    "\n",
    "    # Move McMC chain\n",
    "        imod += 1\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "# Run a new indipendent McMC sampling\n",
    "    ichain += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-processing: compute posterior mean values of the investigated parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AVER_X = np.mean(ALL_X,axis=0)\n",
    "STD_X = np.std(ALL_X,axis=0)\n",
    "\n",
    "AVER_Y = np.mean(ALL_Y,axis=0)\n",
    "STD_Y = np.std(ALL_Y,axis=0)\n",
    "\n",
    "AVER_Z = np.mean(ALL_Z,axis=0)\n",
    "STD_Z = np.std(ALL_Z,axis=0)\n",
    "\n",
    "AVER_T = np.mean(ALL_T,axis=0)\n",
    "STD_T = np.std(ALL_T,axis=0)\n",
    "\n",
    "AVER_VP = np.mean(ALL_VP,axis=0)\n",
    "STD_VP = np.std(ALL_VP,axis=0)\n",
    "\n",
    "\n",
    "print('\\n MEAN PPD  and STD PPD: \\n')\n",
    "print('%20s%10.2f%10.4f%25s%10.2f%10.4f' % ('X: ', AVER_X, STD_X, ' PRIOR MEAN/STD: ', 0.5*(xmin+xmax), (xmax-xmin)/sqrt(12)) )\n",
    "print('%20s%10.2f%10.4f%25s%10.2f%10.4f' % ('Y: ', AVER_Y, STD_Y, ' PRIOR MEAN/STD: ', 0.5*(ymin+ymax), (ymax-ymin)/sqrt(12)) )\n",
    "print('%20s%10.2f%10.4f%25s%10.2f%10.4f' % ('Z: ', AVER_Z, STD_Z, ' PRIOR MEAN/STD: ', 0.5*(zmin+zmax), (zmax-zmin)/sqrt(12)) )\n",
    "print('%20s%10.4f%10.4f%25s%10.4f%10.4f' % ('T: ', AVER_T, STD_T, ' PRIOR MEAN/STD: ', 0.5*(tmin+tmax), (tmax-tmin)/sqrt(12)) )\n",
    "print('%20s%10.2f%10.4f%25s%10.2f%10.4f' % ('Vp: ', AVER_VP, STD_VP, ' PRIOR MEAN/STD: ', 0.5*(vpmin+vpmax), (vpmax-vpmin)/sqrt(12)) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-processing: 1D PPD  of the investigated parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2,ax3,ax4,ax5) = plt.subplots(1, 5, figsize=(15, 3))\n",
    "ax1.title.set_text('1D PPD X' )\n",
    "mu = AVER_X\n",
    "sigma = STD_X\n",
    "n, bins, patches = ax1.hist(ALL_X, 40, density=True)\n",
    "y = ((1 / (np.sqrt(2 * np.pi) * sigma)) *\n",
    "     np.exp(-0.5 * (1 / sigma * (bins - mu))**2))\n",
    "ax1.plot(bins,y,'--')\n",
    "ax1.set_xlim(xmin, xmax)\n",
    "ax1.set_xlabel('Longitude (deg)')\n",
    "ax1.set_ylabel('Frequency')\n",
    "\n",
    "ax2.title.set_text('1D PPD Y' )\n",
    "mu = AVER_Y\n",
    "sigma = STD_Y\n",
    "n, bins, patches = ax2.hist(ALL_Y, 40, density=True)\n",
    "y = ((1 / (np.sqrt(2 * np.pi) * sigma)) *\n",
    "     np.exp(-0.5 * (1 / sigma * (bins - mu))**2))\n",
    "ax2.plot(bins,y,'--')\n",
    "ax2.set_xlim(ymin, ymax)\n",
    "ax2.set_xlabel('Latitude (deg)')\n",
    "\n",
    "ax3.title.set_text('1D PPD Z' )\n",
    "mu = AVER_Z\n",
    "sigma = STD_Z\n",
    "n, bins, patches = ax3.hist(ALL_Z, 40, density=True)\n",
    "y = ((1 / (np.sqrt(2 * np.pi) * sigma)) *\n",
    "     np.exp(-0.5 * (1 / sigma * (bins - mu))**2))\n",
    "ax3.plot(bins,y,'--')\n",
    "ax3.set_xlim(zmin,zmax)\n",
    "ax3.set_xlabel('Depth (m)')\n",
    "\n",
    "ax4.title.set_text('1D PPD Vp' )\n",
    "mu = AVER_VP\n",
    "sigma = STD_VP\n",
    "n, bins, patches = ax4.hist(ALL_VP, 40, density=True)\n",
    "y = ((1 / (np.sqrt(2 * np.pi) * sigma)) *\n",
    "     np.exp(-0.5 * (1 / sigma * (bins - mu))**2))\n",
    "ax4.plot(bins,y,'--')\n",
    "ax4.set_xlim(vpmin,vpmax)\n",
    "ax4.set_xlabel('Vp (m/s)')\n",
    "\n",
    "ax5.title.set_text('1D PPD T0' )\n",
    "mu = AVER_T\n",
    "sigma = STD_T\n",
    "n, bins, patches = ax5.hist(ALL_T, 40, density=True)\n",
    "y = ((1 / (np.sqrt(2 * np.pi) * sigma)) *\n",
    "     np.exp(-0.5 * (1 / sigma * (bins - mu))**2))\n",
    "ax5.plot(bins,y,'--')\n",
    "ax5.set_xlim(tmin,tmax)\n",
    "ax5.set_xlabel('Relative Origin Time(s)')\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-processing: 2D PPD  of the investigated parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "  \n",
    "fig = plt.figure(figsize=(16.2,8))\n",
    "gs = gridspec.GridSpec(nrows=1, ncols=2, wspace=0.2, width_ratios=[1,1])\n",
    "\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "ax1.title.set_text('XY 2D PPD Map of solutions' )\n",
    "ax1.plot(ALL_X, ALL_Y, '.', markersize=10)\n",
    "ax1.set_xlim(xmin_mcmc,xmax_mcmc)\n",
    "ax1.set_ylim(ymin_mcmc,ymax_mcmc)\n",
    "ax1.grid()\n",
    "ax1.plot(event_X, event_Y,marker='*', markersize=20, markerfacecolor='yellow')\n",
    "ax1.plot(x_das, y_das, '.', markersize=1, c='red')\n",
    "ax1.set_ylabel(y_lab)\n",
    "ax1.set_xlabel(x_lab)\n",
    "\n",
    "\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "ax2.title.set_text('XY 2D PPD Map of solutions (ZOOM)' )\n",
    "ax2.plot(ALL_X, ALL_Y, '.', markersize=10)\n",
    "ax2.set_xlim(xmin_zoom,xmax_zoom)\n",
    "ax2.set_ylim(ymin_zoom,ymax_zoom)\n",
    "ax2.grid()\n",
    "ax2.plot(event_X, event_Y,marker='*', markersize=20, markerfacecolor='yellow')\n",
    "ax2.plot(x_das, y_das, '.', markersize=1, c='red')\n",
    "ax2.set_ylabel(y_lab)\n",
    "ax2.set_xlabel(x_lab)\n",
    "\n",
    "\n",
    "outputFigure=\"MCMC_results.jpg\"\n",
    "plt.savefig(outputFigure)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
